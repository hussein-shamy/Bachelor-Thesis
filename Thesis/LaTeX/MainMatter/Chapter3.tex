\setstretch{1}
\setlength{\parskip}{\baselineskip}

%Chapter 3 content goes here.

%Eman

To address the rising network management challenges generated by numerous cellular mobile technologies and their varied layers of cells, self-organizing networks (SONs) for mobile networks were proposed. SON strives to reduce this complexity by automating the majority of the time-consuming, repetitive network management operations such as network element (NE) configuration, optimization, and troubleshooting, minimizing manual effort and human error. As a result, SON is the first generation of network management automation, making mobile networks more sensitive to changes in their operational environment, such as new buildings, weather, and mobility, by reducing long human network problem analysis.

In this chapter, we will delve into the concept of self-healing in mobile communication networks, starting with an overview of self-organizing networks. The main objective of this chapter is to gain a comprehensive understanding of our specific use case, which is coverage area optimization. Additionally, we will explore how we can enhance the efficiency of this use case by leveraging hardware acceleration techniques.


\section{Automating Network Management}

The introduction of network automation features is altering network operations. Initially, certain tasks could be automated by scripting and conducted at specific times or when specific events were registered in the network. Then, with the advent of self-organizing capabilities, more complex modules became available, significantly transforming network operating operations.

\subsection{Traditional Network Operations}

Traditional network operation relies on centralized Operations, Administration, and Maintenance (OAM) architecture, with major network management tasks called FCAPS  (Fault/ Configuration/ Accounting/ Performance/ Security management) performed from a central Operational and Maintenance Centre (OMC). These tasks are human-driven and heavily supervised by the human operator. The process of correlating information from various sources, such as Performance Management (PM)/Fault Management (FM)/Configuration Management (CM), consumes significant network operator resources, making it a time-consuming, expensive, error-prone task. The efficiency of these manual processes still depends on the human operator's expertise. \cite{laiho2006radio}

 The resource-intensive nature of network management processes, requiring specialized human resources and software tools, and their manual execution, make network planning and optimization difficult to respond to short-term variations in the network environment. To compensate, network operators often over-provide network resources to minimize user experience degradation.

\subsection{SON Architecture Types}
SON (Self-Organizing Networks) was introduced as a solution to manage the increasing complexity of network management and improve the efficiency of traditional manual processes. With closed-loop algorithms, SON automates various network management tasks throughout the lifecycle of a mobile network.
By implementing SON-based network operation, resource-intensive and time-consuming tasks can be automated, allowing mobile networks to quickly adapt to changes in network elements and their environment. This agility enables the implementation of new optimization and healing use cases that were not feasible with manual operations, such as real-time coverage outage detection and compensation.
SON functions, responsible for automation, are introduced at different network locations to address specific use cases. 3GPP has defined three architectural options for implementing SON functions within the general 3GPP network management architecture.

\subsubsection{The Key Points of Centralized SON}
\begin{itemize}

\item Centralized SON involves implementing SON functions in a central entity like a Network Manager or Domain Manager.

\item It is suitable for SON use cases with a wider network scope, allowing access to information from multiple network elements.

\item Centralized SON functions can analyze the performance of multiple NEs, coordinate their requirements, and calculate network parameter reconfigurations.

\item Standardized KPIs and measurements via the north-bound interface enable the design of centralized SON functions for multi-vendor environments.

\item Centralized SON requires transporting performance data from individual NEs to the central entity, usually through aggregated intervals.

\item Aggregation sacrifices the short-term dynamics of performance data and increases the response time of SON functions.

\item Centralized SON is more suitable for long-term optimizations that don't require immediate response to changes in NE performance and can tolerate data transfer delays.

\item Centralized SON benefits from greater compute and storage capacity but introduces a single point of failure.

\item Compromised execution of SON functions can impact the performance of a significant portion of the network.

\item Careful consideration is needed to balance computational complexity and potential risks associated with centralized SON implementations.


\end{itemize}



\subsubsection{The Key Points of Distributed SON}
\begin{itemize}

\item Distributed SON functions are implemented at the NE level, specifically at the eNB.

\item They can utilize information from neighboring NEs through interfaces like X2.

\item This implementation option is suitable for SON use cases focusing on a limited scope, such as a single cell or a cluster of neighboring cells.

\item By implementing SON function logic close to the NE performance data source, distributed functions can quickly respond to changes in performance indicators and counters.

\item Distributed implementations are preferred for SON use cases requiring real-time responsiveness and unable to tolerate data transfer delays or aggregated performance data.

\item While most NE parameters are vendor-specific, multi-vendor SON solutions defined by 3GPP can be implemented in a distributed manner.

\item 3GPP has standardized data elements and interfaces for exchanging information among neighboring NEs.

\item Consideration should be given to the limited compute and storage resources of NEs when implementing distributed SON functions.

\item Careful design of SON functions is necessary to manage actions among distributed functions to avoid issues like oscillation, race conditions, and deadlocks.

\item Distributed SON functions offer inherent redundancy, preventing a single point of failure in the network.


\end{itemize}


\subsubsection{The Key Points of Distributed SON}
\begin{itemize}

\item Hybrid SON combines the benefits of centralized and distributed SON implementations.

\item Certain SON functionalities are implemented at central entities like NM or DM.

\item Other functionalities are implemented at the NE level.

\item Centralized functionality primarily handles long-term aspects of network management.

\item Distributed functionality focuses on instantaneous and short-term optimization goals.

\item Central functions establish policies and boundaries for parameter modifications.

\item Distributed functions execute optimization and reconfiguration tasks within those policies and boundaries.

\item Hybrid SON achieves a balanced network management strategy by leveraging the strengths of both centralized and distributed approaches.

\end{itemize}


\section{Self-Configuration}

The deployment and initial configuration of network elements (NEs) require significant resources, including network planning, physical site visits, and configuration efforts. However, with the increasing complexity of HetNet deployments, involving multiple radio access technologies (RATs) and layers of cells, the traditional approach of physical site visits for configuration becomes prohibitively expensive. Automation is crucial during this phase to streamline the deployment process, as recognized by organizations like NGNM. Self-configuration use cases focus on the pre-operational phase, which spans from the NE's physical deployment to its readiness for live network traffic handling. 

Tasks in this phase, also known as 'Plug-and-Play (PnP)', include establishing basic connectivity between the NE and its Operations, Administration, and Maintenance (OAM) system, NE commissioning, and initial radio parameter configuration.


\section{Self-Optimization}
Self-optimization involves optimizing network parameters during the operational stage of a mobile network, while network elements (NEs) are actively handling live network traffic. It is necessary to adjust network configuration parameters to accommodate changes in the network and its environment. Factors such as new constructions, seasonal effects, changes in vegetation, evolving user traffic patterns, and modifications in the network itself can impact the network environment. Additionally, optimization in the operational phase helps overcome limitations in the planning and initial configuration phases, which are based on assumptions about the deployment environment. By analyzing data from various network sources like performance management, fault management, and configuration management, self-optimization algorithms continuously assess the current network performance and propose configuration changes to improve performance in line with network operator objectives. The subsequent sections provide a summary of the essential self-optimization use cases standardized within the LTE-SON framework.

\section{Self-Healing}

Self-Healing also deals with the operational state but focuses on failure detection and recovery, for example, outage detection and NE failure recovery. Due to the distributed nature and large size of mobile networks, FM is a challenging task, which is further accentuated by the fact that in many parts of the network, especially in the radio access network (RAN), there is often little redundancy. Therefore, special SON functions have been created for automating the detection, diagnosis, and recovery of network performance degradation, which are collectively called self-healing SON functions.\cite{laiho2006radio}

Self-Healing is an autonomous property that aims to maintain the system in a healthy state, as opposed to states that are considered faulty or degraded \cite{lehser2010deliverable}. This is achieved through constant system monitoring, detection of unexpected, degraded states, diagnosis of potential root causes, identification of corrective actions, planning their deployment, and monitoring the outcome of the recovery process. Unlike self-optimization, self-healing functions primarily focus on monitoring network performance degradation symptoms, without prior knowledge of the root causes.


The self-healing concepts and requirements are defined in 3GPP technical specification 3GPP TS 32.541 \cite{3gpp2014telecommunication}. In addition, there are four documents specifying the Information Service (IS) and Solution Sets (SSs) for the SON Policy NRM IRP. 3GPP identifies three main use cases: software faults, hardware faults, and cell outage detection and compensation.


For software faults, the corrective actions include software initialization and restarts on different levels, and if this is not able to solve the problem, re-installing and possibly reverting either to a backup of an earlier software version or an activation of a fall-back software load. Alternatively, software issues can be attempted to be resolved with reconfigurations, but this requires a reliable diagnosis of the problem [12]. In the case of faulty hardware, the recovery depends on whether there is a redundant backup unit for the failing resource. If there is no redundancy, the corrective actions can include isolating the faulty resource and trying to circumvent or work around the failure by reconfiguring the other working resources. If there is redundancy, then the recovery would be executed with a switchover using the necessary reconfigurations.

\subsection{Next-Generation Self-Healing Networks: Cognitive Autonomy}

While self-optimization functions optimize a set of configuration parameters to improve the network performance from a given network state, the self-healing functions focus on ensuring that the network can fulfil its purpose and serve its customers even in case of failures,unexpected changes, or events that risk a degradation in the network performance \cite{sartori2012self}. In other words, their objective is to make the network more resilient \cite{zolli2012resilience,mwanje2016network}. This section discusses the methods for improving resiliency of future cognitive autonomous networks. In particular, concepts for cognitive self-healing functions.

\subsection{Resilience and Self-Healing}

Resiliency is the capability of a system to recover to a stable, functioning state after failure or adverse events \cite{zolli2012resilience}. By definition, it is not the same as robustness. A robust system is strongly designed to withstand any foreseen problems or failures but may be too rigid and fail to survive and adapt in case of unforeseen circumstances, which are inevitably bound to happen in complex systems. For example, a farmer may prepare his crop against fire, flooding, and local pests, but the crop can be destroyed by a foreign plant virus introduced in the environment. Paradoxically, a very robust system can sometimes be more susceptible to failure due to its increased rigidness and complexity \cite{zolli2012resilience}. Modern mobile telephone networks are often said to be amongst the largest and most complex human-created systems and their distributed nature makes them even more complex to manage and predict. So, simple robust design principles (redundancy etc.) are not sufficient to ensure ultra-reliable network performance required for many 5G use cases, such as remote surgery.

Making networks more robust and redundant makes them more complex which, in turn, may create new possibilities for failures. It can also make the problems harder to diagnose, when they occur. This also applies to the self-healing functions. The functions may not always be able to diagnose the complex causes and effects that lead to the degradation and the applied corrections can sometimes be rather work-arounds than really addressing the root cause. Such work-arounds remedy the immediate symptoms, but since the root cause has not been resolved,the problem may still appear later. A risk is that at a later, more escalated stage, the problem may be more severe and harder to troubleshoot and correct.

Monitoring the corrective actions performed by self-healing functions is crucial. However, it is important to avoid triggering erroneous corrective actions, which can result in system faults. This scenario is similar to an allergic reaction caused by the human immune system. To prevent false positive triggers, additional verification layers can be implemented, but this adds complexity to the system. Striking the right balance between robustness and complexity is essential when implementing self-healing mechanisms.

\subsection{Overview on Cognitive Self-Healing}

Self-healing represents the ideal state of automation, where a system can recover from any failure. However, achieving such a perfect self-healing system is an immensely complex task. To tackle this complexity, it is necessary to break down the system structure into smaller, simpler components that focus on limited functionality. Gradually, as these simpler components solidify, complexity can be added to enhance their capabilities. This incremental approach allows for a more manageable development of a self-healing system.

\subsection{The Basic Building Blocks of Self-Healing}
The simplest self-healing solutions are rule-based systems, that trigger a specified automated corrective action when a given condition is fulfilled, e.g. by a specified alarm. Such systems only work reliably on anticipated problems and typically under-perform in unforeseen circumstances, or in changing environments. Furthermore, the creation and maintenance of the rule base is expensive and laborious. Rule-based self-healing functions are very rigid and, because of this, rigidity can even make the system less resilient against unexpected changes\cite{ali2018self}.

The rules governing which corrective actions to trigger and when, can be formulated as a classification problem and learned through machine learning. In this context, the network or network element can reside in one of many states, where each state describes either normal or degraded operation. Degraded states can be connected to one or more corrective workflows. Since the anomalous or degraded states are, by definition, rare the rules are learned on a skewed training dataset. If the system learns to detect degraded states from examples, it may also fail to recognize new, unforeseen problematic states. An additional complication can be the scarcity of such labelled training datasets, a topic that will be discussed later\cite{ali2018self}.

The implementation of self-healing functions typically involves a four-step process: profiling the normal states of the system, detecting anomalies or deviations from the normal, diagnosing the detected anomalies, and performing corrective actions. This process is illustrated in Figure 9.2. By learning and profiling the normal behavior of the system, any deviations from it, even unexpected ones, can be identified. However, not all deviations indicate degradations, so a diagnosis function is necessary to connect the detected anomalies with possible corrective actions. Moreover, to adapt to changes in network behavior over time, such as trends or seasonal variations in network traffic characteristics, the profiles of normal states should be able to adjust accordingly.

The four steps in the self-healing process are interdependent, with each stage building upon the results of the previous one. The reliability of the earlier stages becomes crucial for the overall performance of the self-healing process. The initial stages of profiling and anomaly detectionare comparatively simpler, while the complexity increases for both training and runtime decision-making. The most complex step is determining the appropriate corrective action to take. This complexity arises from the large problem space and the need for generalization and application of knowledge across similar but different domains or tasks. Achieving this ability is challenging in machine learning and artificial intelligence. As we move further to the right of Figure 9.2, there is likely to be a greater need for human operator involvement.


\subsection{Self-healing Framework for Mobile Networks}

As the number of physical entities in a network increases, the likelihood of network outages, both full and partial, also increases. To address these outages, self-healing solutions typically employ a 3-stage framework.

The first stage involves detecting network outages using outage detection algorithms. Effective self-healing requires the ability to detect both full and partial outages. When a network outage is detected, the affected network node is flagged for further action based on the type of outage. For example, if a cell experiences hardware failure, it will be flagged for self-healing.

Once an outage is detected, diagnostic algorithms are executed to identify the exact cause of the network outage. For instance, in the case of hardware failure, the detection algorithm examines alarms and fault codes to determine the failed hardware component. This informationis then communicated to the Network Controller, which can command field teams to replace the failed component or activate redundancy elements as necessary.

After completing the outage diagnosis, the information is passed to the final stage of the self-healing function, which is outage compensation. In this stage, the self-healing function assesses the impact of the outage on neighboring entities and subscribers. This information is used to implement changes that mitigate the outage. For example, if there is a hardware failure, the outage compensation solution identifies coverage gaps and makes adjustments in neighboring cells to provide temporary coverage for affected subscribers. In the case of a partial outage, emergency parameter changes may be executed at the affected cell or its neighbors to recover degraded key performance indicators (KPIs).

The complete self-healing framework, along with relevant studies, is depicted in Figure 4. Additionally, Figure 5 presents a taxonomy of studies based on these framework components.

\subsection{Key Components of Self-Healing Techniques\\}

\subsubsection{Methodology}

Studies presenting solutions for the detection, diagnosis, and compensation of outages can be categorized into three main methodologies: heuristic, analytical, and learning based.


\begin{itemize}
\item  Heuristic solutions rely on pre-defined rules and incorporate intuition or prior knowledge derived from existing literature or experience.

\item  Analytical solutions involve breaking down a problem into its mathematical components and solving them to obtain optimal or near-optimal solutions.

\item Learning-based solutions utilize machine learning techniques, commonly used in computer science, to develop solutions by learning patterns and making predictions based on data.


\end{itemize}


These three methodologies provide different approaches for addressing outages and offer a range of techniques to improve the self-healing capabilities of networks.


\subsubsection{Network Topology}

Network topology refers to the arrangement or structure of a network, particularly in terms of cell deployments. It describes the hierarchical organization of the network. There are two primary types of network topologies: homogeneous and heterogeneous.

Homogeneous networks consist of a single tier of cells. These cells can either be macro cells, which have broad coverage areas, or small cells with lower power and coverage capabilities.On the other hand, heterogeneous networks, also known as HetNets, comprise a combination of macro and small cells, forming a multi-tier cellular network. This mix of cell types enables enhanced coverage, capacity, and network performance.

While most studies on legacy mobile cellular networks employ homogeneous network topology as the baseline, HetNets are quickly gaining popularity due to their flexibility and their potential to achieve the goals set out for 5G cellular networks \cite{andrews2014will}.

\subsubsection{Performance Metrics}

Network performance metrics are essential for evaluating the performance of a network, and they can be derived from various sources such as network entities and user reports. The selection of performance metrics plays a crucial role in the development and assessment of solutions and algorithms in any study.

In the context of Self-healing, performance metrics related to network health are particularly relevant. These metrics provide insights into the overall state and well-being of the network, allowing for the identification of issues and the effectiveness of Self-healing mechanisms. By monitoring and analyzing network health metrics, researchers and practitioners can better understand the impact of outages, faults, and other factors on the network's performance and take appropriate actions to improve its resilience and stability.

Network health is a broad term used to describe the performance of the network in terms of universally accepted KPIs such as Accessibility, Retainability and Mobility \cite{andrews2014will}.

Accessibility refers to the capability of subscribers to connect to the network and access its resources for data transmission. It is assessed through various key performance indicators (KPIs) such as attach success rate, radio resource control setup success rate, connection setup success rate, and random access success rate. These metrics measure the effectiveness of the network in enabling subscribers to establish and maintain connections.

Retainability measures the network's ability to sustain a data session without any disruptions or drops. The session drop rate KPI is used to evaluate retainability, indicating the rate at which data sessions are prematurely terminated. A lower session drop rate signifies better retainability and a more reliable network.

Mobility evaluates the network's capability to support seamless subscriber transitions between different cells without significant impact on services. It is typically represented by handover attempt rate, handover success rate, and handover failure rate KPIs. These metrics indicate how effectively the network manages handovers, ensuring smooth transitions for subscribers as they move between cells while maintaining uninterrupted service quality.

Moreover, network coverage and quality are crucial aspects considered in the design and analysis of Self-healing solutions. Various measurements are utilized to assess these factors. Network coverage is evaluated using metrics such as reference signal received power (RSRP), which indicates the strength of the received signal. Network quality, on the other hand, involves assessing parameters such as spectral efficiency, signal-to-interference, and noise ratio (SINR), reference signal received quality (RSRQ), network and user data throughputs, channel quality indicators, and data latency. These measurements provide valuable insights into the performance and efficiency of the network, enabling effective Self-healing strategies to be developed and implemented.

\subsubsection{ Control Mechanism}

The control mechanism of a SON solution determines how the functionality of the solution is managed. It can be categorized into three methods: centralized, distributed, and hybrid.In centralized control, the SON functions are controlled from a single central controller that is connected to every node in the network.
In distributed control, the control of SON functions is decentralized, and each network node has the ability to manage its own SON functions.

Hybrid control is a combination of centralized and distributed control. In this approach, some SON functions are located within a centralized controller, while other less computationallyintensive functions that do not directly impact neighboring nodes are distributed among the network nodes.

\subsubsection{Direction of Control}

The direction of control in a SON function determines whether it is focused on optimizing the node-to-user link, the user-to-node link, or both. SON functions that prioritize optimizing the node-to-user link are known as downlink controlled, as they aim to enhance the performance of data transmission from the network node to the user. Conversely, functions that prioritize optimizing the user-to-node link are referred to as uplink controlled, as they aim to improve the performance of data transmission from the user to the network node. There are also SON functions that optimize both the downlink and uplink, providing bidirectional control for enhancing network performance.

\subsubsection{Taxonomy for Self-Healing Concept}

The proposed taxonomy for self-healing in mobile networks is structured as follows:
\begin{enumerate}
	\item  Outage Detection:
	\begin{itemize}
		\item Full Outage Detection
		\item Partial Outage Detection
	\end{itemize}

\item Outage Diagnosis:
	\begin{itemize}
	\item Full Outage Detection
	\item Partial Outage Detection
    \end{itemize}

\item Outage Compensation:
     \begin{itemize}
      \item Coverage Area Optimizationb.
      \item SINR Optimizationc.
       \item Cell Capacity Optimization.
       \item Spectral Efficiency Optimization
      \end{itemize}
\end{enumerate} 


This taxonomy categorizes self-healing functionalities into three main stages: detection, diagnosis, and compensation. The detection stage focuses on identifying network outages, distinguishing between full and partial outages. The diagnosis stage involves determining the specific causes of the outages, differentiating between full and partial cases. Finally, the compensation stage addresses the optimization of various aspects, such as coverage area, SINR, cell capacity, and spectral efficiency, to mitigate the impact of the outages and enhance network performance.


\section{Coverage Area Optimization for Outage Compensation}

The component of outage compensation holds a central role in the Self-healing framework, and as a result, it has garnered significant interest and research focus within the academic community. Compensation actions and algorithms are specifically designed to restore service temporarily in the event of a full or partial outage, as both scenarios cannot be immediatelyresolved. While the methodologies for detecting and diagnosing full outages and partial outages may differ, the compensatory techniques employed for both events exhibit similarities. Although many studies primarily address compensation algorithms for full outages, these solutions can also be applied effectively to address partial outages.

The key principle of outage compensation is to leverage resources from neighboring cells of outage-affected cells to provide temporary services in affected area. These resources include cell bandwidth and user associations which can be modified using primary parameters such as cell/user equipment transmit powers, and antenna parameters as well as secondary parameters such as neighbor lists and cell selection parameters \cite{amirijoo2009cell}.

This section focuses on the presentation of coverage area optimization algorithms, which play a crucial role in our case study. The algorithms are described in detail, highlighting the methodology employed. Coverage area optimization is an essential aspect of our work, making this section particularly significant.

Table V presents a compilation of studies \cite{zoha2016learning,onireti2015cell,asghar2012self, amirijoo2011effectiveness, frenzel2012automated, jiang2013cell, wenjing2012centralized} that have addressed the issue of network outages and KPI degradations by proposing outage compensation. algorithms with a specific focus on coverage optimization. The table provides an overview of these studies and the techniques they have proposed.


\subsection{Choosing the right neighboring cells, optimization parameters, and recovery action:}

In the context of outage compensation, three important aspects are discussed: the choice of neighboring cells, optimization parameters, and recovery actions. Several studies have investigated these areas, namely \cite{asghar2012self,amirijoo2011effectiveness,frenzel2012automated}.

In the study by Asghar et al. \cite{asghar2012self}, a Self-healing framework is proposed, which utilizes received power measurements from users in outage-affected cells to create coverage polygons for neighboring cells. The algorithm iteratively adjusts the antenna configurations of key neighboring cells to ensure coverage constraints are met for all users. By monitoring downlink throughputs and radio link failures, the algorithm benchmarks network recovery. Real network outage demonstrations show that this algorithm effectively compensates for outages within 2 hours.

Amirijoo et al. \cite{amirijoo2011effectiveness} present an outage compensation framework that compares the potential of different control parameters (such as reference signal power, uplink target received power level P0, and antenna tilt) in mitigating outage-induced performance degradation. Using an iterative algorithm, the parameters of neighboring cells are updated and their results are evaluated. The findings indicate that P0 and antenna tilt are the most effective parameters for improving coverage, while P0 is most effective for enhancing throughput.

In the work by Frenzel et al. \cite{frenzel2012automated}, the authors discuss the selection of an optimal recovery action based on three inputs: the probability of effectiveness of a solution (dependent on the outage cause), the network operator's preference for a recovery action, and the operator's preference for a degradation resolution. They propose a weighted-sum function that calculates the cost of selecting a solution, action, and resolution tuple. The framework is adaptable to different network technologies, allowing for the inclusion of additional tuples in futurenetworks. However, determining probabilities and preferences requires manual input from experts.
These studies shed light on the significance of choosing the right neighboring cells, optimization parameters, and recovery actions in developing effective outage compensation solutions within the Self-healing framework.

\subsection{Non-convex Coverage Optimization Techniques for Outage Compensation:}

Jiang et al. \cite{jiang2013cell} and Wenjing et al. \cite{wenjing2012centralized} address the challenge of outage compensation using non-convex optimization methods. They recognize that in large networks with diverse optimization parameters, outage compensation can be a non-convex problem that is computationally complex and difficult to solve optimally. Converting the problem into a convex one would require numerous generalizations and assumptions, which may not be practical for real-world implementation.

Jiang et al. \cite{jiang2013cell} propose a cost function minimization approach for coverage optimization. They use a weighted sum of downlink channel quality and received signal strength as the cost function. The authors apply an immune algorithm, a non-convex optimization technique, to maximize the cost function and determine the optimal uplink target received power (P0) for outage compensation. The immune algorithm demonstrates improved coverage and channel quality after optimization, converging quickly. Compared to other techniques, their methodology significantly enhances coverage by 10\% without sacrificing cell edge throughput. However, the immune algorithm's performance is sensitive to the selection of initial parameters, as incorrect settings may result in an infeasible solution.

Similarly, Wenjing et al. \cite{wenjing2012centralized} address the non-convex problem of minimizing coverage holes and pilot pollution using downlink pilot powers of neighboring cells for outage compensation. They employ a particle swarm algorithm, another non-convex optimization technique, to tacklethis problem. The analysis of the algorithm shows that it is highly efficient in terms of execution time while recovering over 98\% of the coverage area in terms of signal strength without significant degradation in link quality. Similar to the immune algorithm, the particle swarm algorithm's convergence is highly dependent on the initialization parameters.

Both studies highlight the effectiveness of non-convex optimization methods for outage compensation, overcoming the limitations of converting the problem into a convex one. The immune algorithm and particle swarm algorithm offer promising results in improving coverage and addressing specific challenges related to outage compensation. However, careful consideration of initialization parameters is necessary to ensure optimal convergence.

\subsection{Learning-based Coverage Optimization Solutions for Outage Compensation:}

Outage Compensation: Learning-based algorithms have shown promise in outage detection and diagnosis, primarily through classification and clustering techniques. However, reinforcement learning emerges as the most effective approach for outage compensation due to its ability to identify optimal strategies based on maximum rewards over a learning period.

Zoha et al. \cite{zoha2016learning} propose a reinforcement learning-based solution for outage compensation within a comprehensive Self-healing framework. Their algorithm utilizes fuzzy logic-based reinforcement learning to adjust antenna tilts and cell transmit powers, aiming to achieve desirable compensated performance in terms of cell coverage. The compensation algorithm iteratively modifies optimization parameters using exploration of new rewards or exploitation of past rewards. The reinforcement learning database interprets the resulting network state through a fuzzy-logic regulator, determining whether it is better or worse than the previous state and guiding the next step of the algorithm. The authors demonstrate that their solution canenhance post-outage cell edge coverage by 5 dB while restoring the mean data rate to pre-outage levels.

Onireti et al. \cite{onireti2015cell} present a similar approach to Zoha et al. \cite{zoha2016learning}, but tailored for heterogeneous networks. In their solution, they replace the fuzzy logic component with an actor-critic module to facilitate reinforcement learning. The actor-critic module performs exploratory or exploitative actions, such as adjusting antenna tilt or transmit power of neighboring cells, based on the learned probability of rewards over time. The critic evaluates the reward associated with the action taken and updates past rewards and probabilities accordingly. Comparative analysis with Zoha et al.'s solution shows that this approach improves cell coverage and channel quality, particularly for cell edge users, bringing them closer to pre-outage levels.

Both studies demonstrate the effectiveness of reinforcement learning in outage compensation algorithms. By leveraging rewards and probabilities learned over time, these learning-based solutions adapt optimization parameters to mitigate the impact of outages and enhance network performance, ultimately improving cell coverage and channel quality.


